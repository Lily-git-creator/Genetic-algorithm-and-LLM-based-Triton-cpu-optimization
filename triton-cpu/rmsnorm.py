import torch
import triton
import triton.language as tl
import time
import math

# Triton RMSNorm å†…æ ¸ - é’ˆå¯¹CPUä¼˜åŒ–
@triton.jit
def rms_norm_kernel(
    # è¾“å…¥/è¾“å‡ºæŒ‡é’ˆ
    input_ptr, weight_ptr, output_ptr,
    # å¼ é‡ç»´åº¦ä¿¡æ¯
    n_elements,  # æ¯ä¸ªæ ·æœ¬çš„ç‰¹å¾æ•° (æ ‡å‡†åŒ–ç»´åº¦)
    stride_batch, stride_feature,  # è¾“å…¥å¼ é‡çš„å†…å­˜æ­¥é•¿
    # å‚æ•°
    eps: tl.constexpr,
    # å¹³é“ºå‚æ•°
    BLOCK_SIZE: tl.constexpr,
):
    """
    RMSNorm å†…æ ¸: output = (input / sqrt(mean(input^2) + eps)) * weight
    
    è®¡ç®—è¿‡ç¨‹:
    1. è®¡ç®—è¾“å…¥å¼ é‡çš„å¹³æ–¹çš„å‡å€¼ (RMS)
    2. ä½¿ç”¨ RMS å¯¹è¾“å…¥è¿›è¡Œæ ‡å‡†åŒ–
    3. åº”ç”¨å¯å­¦ä¹ çš„æƒé‡å‚æ•°
    """
    # å½“å‰ç¨‹åºå¤„ç†çš„æ‰¹æ¬¡ç´¢å¼•
    batch_idx = tl.program_id(axis=0)
    
    # è®¡ç®—å½“å‰æ‰¹æ¬¡åœ¨å†…å­˜ä¸­çš„èµ·å§‹åç§»
    input_batch_start = batch_idx * stride_batch
    output_batch_start = batch_idx * stride_batch
    
    # ====== æ­¥éª¤1: è®¡ç®— RMS (å‡æ–¹æ ¹) ======
    mean_square = tl.zeros((1,), dtype=tl.float32)
    
    # åˆ†å—è®¡ç®—å¹³æ–¹å’Œ (å‡å°‘å†…å­˜å‹åŠ›)
    for offset in range(0, n_elements, BLOCK_SIZE):
        col_idx = offset + tl.arange(0, BLOCK_SIZE)
        mask = col_idx < n_elements
        
        # åŠ è½½å½“å‰å—çš„æ•°æ®
        input_vals = tl.load(
            input_ptr + input_batch_start + col_idx * stride_feature,
            mask=mask,
            other=0.0,
        )
        
        # ç´¯åŠ å¹³æ–¹å€¼
        mean_square += tl.sum(input_vals * input_vals, axis=0)
    
    # è®¡ç®—å‡å€¼å¹¶åŠ ä¸Š epsilon
    rms = tl.sqrt(mean_square / n_elements + eps)
    
    # ====== æ­¥éª¤2: åº”ç”¨æ ‡å‡†åŒ–å’Œæƒé‡ ======
    for offset in range(0, n_elements, BLOCK_SIZE):
        col_idx = offset + tl.arange(0, BLOCK_SIZE)
        mask = col_idx < n_elements
        
        # é‡æ–°åŠ è½½è¾“å…¥æ•°æ®
        input_vals = tl.load(
            input_ptr + input_batch_start + col_idx * stride_feature,
            mask=mask,
            other=0.0,
        )
        
        # åŠ è½½æƒé‡ (å¹¿æ’­åˆ°æ•´ä¸ªæ‰¹æ¬¡)
        weight_vals = tl.load(
            weight_ptr + col_idx * stride_feature,
            mask=mask,
            other=1.0,  # é»˜è®¤æƒé‡ä¸º1
        )
        
        # RMSNorm è®¡ç®—: (input / rms) * weight
        normalized = (input_vals / rms) * weight_vals
        
        # å­˜å‚¨ç»“æœ
        tl.store(
            output_ptr + output_batch_start + col_idx * stride_feature,
            normalized,
            mask=mask,
        )

def triton_rms_norm(input_tensor, weight, eps=1e-5):
    """
    Triton RMSNorm å®ç°
    
    å‚æ•°:
        input_tensor: [batch_size, feature_dim] è¾“å…¥å¼ é‡
        weight: [feature_dim] å¯å­¦ä¹ çš„ç¼©æ”¾æƒé‡
        eps: é˜²æ­¢é™¤é›¶çš„å°å¸¸æ•°
    
    è¿”å›:
        normalized: [batch_size, feature_dim] æ ‡å‡†åŒ–åçš„å¼ é‡
    """
    # éªŒè¯è¾“å…¥ç»´åº¦
    assert input_tensor.dim() == 2, "è¾“å…¥å¿…é¡»æ˜¯äºŒç»´å¼ é‡ [batch_size, feature_dim]"
    assert weight.dim() == 1, "æƒé‡å¿…é¡»æ˜¯ä¸€ç»´å¼ é‡ [feature_dim]"
    assert input_tensor.shape[1] == weight.shape[0], "ç‰¹å¾ç»´åº¦å¿…é¡»åŒ¹é…"
    
    batch_size, feature_dim = input_tensor.shape
    
    # åˆ†é…è¾“å‡ºå¼ é‡
    output = torch.empty_like(input_tensor)
    
    # é…ç½®å†…æ ¸å‚æ•°
    BLOCK_SIZE = 128  # å¯æ ¹æ®CPUç¼“å­˜è°ƒæ•´
    
    # å®šä¹‰ä¸€ç»´ç½‘æ ¼ (æ¯ä¸ªæ‰¹æ¬¡ä¸€ä¸ªçº¿ç¨‹)
    grid = (batch_size,)
    
    # å¯åŠ¨å†…æ ¸
    rms_norm_kernel[grid](
        input_tensor, weight, output,
        feature_dim,
        input_tensor.stride(0), input_tensor.stride(1),
        eps,
        BLOCK_SIZE=BLOCK_SIZE,
    )
    
    return output

# ====== å‚è€ƒå®ç° (PyTorch) ======
def pytorch_rms_norm(x, weight, eps=1e-5):
    """PyTorch å‚è€ƒå®ç°"""
    # è®¡ç®— RMS
    rms = torch.sqrt(torch.mean(x**2, dim=-1, keepdim=True) + eps)
    # æ ‡å‡†åŒ–å¹¶åº”ç”¨æƒé‡
    return (x / rms) * weight

def test_rms_norm():
    """æµ‹è¯• RMSNorm ç®—å­çš„æ­£ç¡®æ€§å’Œæ€§èƒ½"""
    print("ğŸ§ª å¼€å§‹ RMSNorm ç®—å­æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•é…ç½®
    test_configs = [
        # (batch_size, feature_dim, æè¿°)
        (32, 512, "å°æ‰¹é‡ - å°å‹ç‰¹å¾"),
        (128, 4096, "ä¸­ç­‰æ‰¹é‡ - LLMå…¸å‹éšè—å±‚"),
        (512, 1024, "å¤§æ‰¹é‡ - ä¸­å‹ç‰¹å¾"),
        (16, 16384, "å°æ‰¹é‡ - è¶…å®½ç‰¹å¾"),
    ]
    
    # ç²¾åº¦å®¹å·®
    rtol, atol = 1e-4, 1e-5
    
    for batch_size, feature_dim, desc in test_configs:
        print(f"\nğŸ“Š æµ‹è¯•é…ç½®: {desc}")
        print(f"   æ‰¹æ¬¡å¤§å°: {batch_size}, ç‰¹å¾ç»´åº¦: {feature_dim}")
        
        # ç”Ÿæˆéšæœºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        x = torch.randn(batch_size, feature_dim, device='cpu', dtype=torch.float32)
        weight = torch.randn(feature_dim, device='cpu', dtype=torch.float32)
        
        # é¢„çƒ­ (é¿å…é¦–æ¬¡è¿è¡Œå¼€é”€)
        if batch_size == test_configs[0][0]:
            print("   é¢„çƒ­è¿è¡Œ...")
            _ = triton_rms_norm(x[:2], weight)
            _ = pytorch_rms_norm(x[:2], weight)
        
        # ====== Triton å®ç° ======
        torch.cuda.synchronize() if x.is_cuda else None
        start_time = time.perf_counter()
        triton_result = triton_rms_norm(x, weight)
        torch.cuda.synchronize() if x.is_cuda else None
        triton_time = time.perf_counter() - start_time
        
        # ====== PyTorch å‚è€ƒå®ç° ======
        torch.cuda.synchronize() if x.is_cuda else None
        start_time = time.perf_counter()
        pytorch_result = pytorch_rms_norm(x, weight)
        torch.cuda.synchronize() if x.is_cuda else None
        pytorch_time = time.perf_counter() - start_time
        
        # ====== æ­£ç¡®æ€§éªŒè¯ ======
        # è®¡ç®—æœ€å¤§ç»å¯¹è¯¯å·®å’Œç›¸å¯¹è¯¯å·®
        abs_diff = torch.abs(triton_result - pytorch_result)
        max_abs_error = torch.max(abs_diff).item()
        
        # ç›¸å¯¹è¯¯å·® (é¿å…é™¤é›¶)
        rel_diff = abs_diff / (torch.abs(pytorch_result) + 1e-8)
        max_rel_error = torch.max(rel_diff).item()
        
        is_correct = torch.allclose(
            triton_result, pytorch_result, 
            rtol=rtol, atol=atol
        )
        
        # ====== æ€§èƒ½åˆ†æ ======
        # è®¡ç®—æµ®ç‚¹è¿ç®—æ¬¡æ•° (è¿‘ä¼¼)
        # æ¯ä¸ªå…ƒç´ : å¹³æ–¹(1), åŠ æ³•(1), å¼€æ–¹(1), é™¤æ³•(1), ä¹˜æ³•(2) â‰ˆ 6 FLOPs
        flops_per_element = 6
        total_flops = batch_size * feature_dim * flops_per_element
        
        triton_gflops = (total_flops / triton_time) / 1e9
        pytorch_gflops = (total_flops / pytorch_time) / 1e9
        speedup = pytorch_time / triton_time
        
        # ====== æ‰“å°ç»“æœ ======
        print(f"   âœ… æ­£ç¡®æ€§: {'PASS' if is_correct else 'FAIL'}")
        if not is_correct:
            print(f"      æœ€å¤§ç»å¯¹è¯¯å·®: {max_abs_error:.2e}")
            print(f"      æœ€å¤§ç›¸å¯¹è¯¯å·®: {max_rel_error:.2e}")
        
        print(f"   âš¡ æ€§èƒ½å¯¹æ¯”:")
        print(f"     - Triton:  {triton_time*1000:6.2f} ms, {triton_gflops:5.2f} GFLOP/s")
        print(f"     - PyTorch: {pytorch_time*1000:6.2f} ms, {pytorch_gflops:5.2f} GFLOP/s")
        print(f"     åŠ é€Ÿæ¯”: {speedup:.2f}x {'(Tritonæ›´å¿«)' if speedup > 1.0 else '(PyTorchæ›´å¿«)'}")
        
        # ====== é¢å¤–éªŒè¯: RMS è®¡ç®—æ­£ç¡®æ€§ ======
        if batch_size <= 4:  # åªå¯¹å°æ‰¹æ¬¡æ‰“å°è¯¦ç»†éªŒè¯
            print(f"\n   ğŸ” è¯¦ç»†éªŒè¯ (å‰2ä¸ªæ ·æœ¬):")
            for i in range(min(2, batch_size)):
                # è®¡ç®— Triton çš„ RMS
                rms_triton = torch.sqrt(torch.mean(triton_result[i]**2))
                # è®¡ç®— PyTorch çš„ RMS
                rms_pytorch = torch.sqrt(torch.mean(pytorch_result[i]**2))
                print(f"      æ ·æœ¬ {i}: Triton RMS={rms_triton:.4f}, PyTorch RMS={rms_pytorch:.4f}")
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•å®Œæˆï¼")
    
    # è¿”å›æœ€åä¸€ä¸ªæµ‹è¯•çš„ç»“æœç”¨äºè¿›ä¸€æ­¥åˆ†æ
    return triton_result, pytorch_result

# ====== ä¸»å‡½æ•° ======
if __name__ == "__main__":
    print("ğŸš€ Triton-CPU RMSNorm ç®—å­æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    # è¿è¡Œä¸»æµ‹è¯•
    triton_result, pytorch_result = test_rms_norm()

'''
python ./rmsnorm.py
ğŸš€ Triton-CPU RMSNorm ç®—å­æµ‹è¯•å¥—ä»¶
============================================================
ğŸ§ª å¼€å§‹ RMSNorm ç®—å­æµ‹è¯•
============================================================

ğŸ“Š æµ‹è¯•é…ç½®: å°æ‰¹é‡ - å°å‹ç‰¹å¾
   æ‰¹æ¬¡å¤§å°: 32, ç‰¹å¾ç»´åº¦: 512
   é¢„çƒ­è¿è¡Œ...
   âœ… æ­£ç¡®æ€§: PASS
   âš¡ æ€§èƒ½å¯¹æ¯”:
     - Triton:    0.27 ms,  0.37 GFLOP/s
     - PyTorch:   0.13 ms,  0.75 GFLOP/s
     åŠ é€Ÿæ¯”: 0.49x (PyTorchæ›´å¿«)

ğŸ“Š æµ‹è¯•é…ç½®: ä¸­ç­‰æ‰¹é‡ - LLMå…¸å‹éšè—å±‚
   æ‰¹æ¬¡å¤§å°: 128, ç‰¹å¾ç»´åº¦: 4096
   âœ… æ­£ç¡®æ€§: PASS
   âš¡ æ€§èƒ½å¯¹æ¯”:
     - Triton:    3.64 ms,  0.86 GFLOP/s
     - PyTorch:   2.97 ms,  1.06 GFLOP/s
     åŠ é€Ÿæ¯”: 0.81x (PyTorchæ›´å¿«)

ğŸ“Š æµ‹è¯•é…ç½®: å¤§æ‰¹é‡ - ä¸­å‹ç‰¹å¾
   æ‰¹æ¬¡å¤§å°: 512, ç‰¹å¾ç»´åº¦: 1024
   âœ… æ­£ç¡®æ€§: PASS
   âš¡ æ€§èƒ½å¯¹æ¯”:
     - Triton:    3.74 ms,  0.84 GFLOP/s
     - PyTorch:   0.92 ms,  3.41 GFLOP/s
     åŠ é€Ÿæ¯”: 0.25x (PyTorchæ›´å¿«)

ğŸ“Š æµ‹è¯•é…ç½®: å°æ‰¹é‡ - è¶…å®½ç‰¹å¾
   æ‰¹æ¬¡å¤§å°: 16, ç‰¹å¾ç»´åº¦: 16384
   âœ… æ­£ç¡®æ€§: PASS
   âš¡ æ€§èƒ½å¯¹æ¯”:
     - Triton:    1.87 ms,  0.84 GFLOP/s
     - PyTorch:   8.91 ms,  0.18 GFLOP/s
     åŠ é€Ÿæ¯”: 4.76x (Tritonæ›´å¿«)

============================================================
æµ‹è¯•å®Œæˆï¼
'''